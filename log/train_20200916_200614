2020-09-16 20:06:14,517 INFO    : Pytorch 1.5.0
2020-09-16 20:06:14,517 INFO    : [INFO] Create Vocab, vocab path is cache/cnndm/vocab
2020-09-16 20:06:14,520 INFO    : [INFO] max_size of vocab was specified as 1000; we now have 1000 words. Stopping reading.
2020-09-16 20:06:14,520 INFO    : [INFO] Finished constructing vocabulary of 1000 total words. Last word added: europe
2020-09-16 20:06:14,521 INFO    : Namespace(atten_dropout_prob=0.1, batch_size=2, bidirectional=True, cache_dir='cache/cnndm', cuda=False, data_dir='datasets/cnndm', doc_max_timesteps=50, embed_train=False, embedding_path='./Glove/glove.42B.300d.txt', feat_embed_size=50, ffn_dropout_prob=0.1, ffn_inner_hidden_size=512, gpu='0', grad_clip=False, log_root='log/', lr=0.0005, lr_descent=False, lstm_hidden_state=128, lstm_layers=2, m=3, max_grad_norm=1.0, n_epochs=20, n_feature_size=128, n_head=2, n_layers=1, recurrent_dropout_prob=0.1, restore_model='None', save_root='save/', sent_max_len=5, use_orthnormal_init=True, vocab_size=1000, word_emb_dim=4, word_embedding=True)
2020-09-16 20:06:14,529 INFO    : [MODEL] ExtComAbs 
2020-09-16 20:06:14,530 INFO    : [INFO] Start reading ExampleSet
2020-09-16 20:06:14,540 INFO    : [INFO] Finish reading ExampleSet. Total time is 0.010142, Total size is 309
2020-09-16 20:06:14,540 INFO    : [INFO] Start reading ExampleSet
2020-09-16 20:06:14,551 INFO    : [INFO] Finish reading ExampleSet. Total time is 0.010598, Total size is 281
2020-09-16 20:06:14,551 INFO    : [INFO] Create new model for training...
2020-09-16 20:06:14,552 INFO    : [INFO] Starting run_training
2020-09-16 20:06:19,999 INFO    :        | end of iter   0 | time:  4.91s | train loss 0.6749 | 
2020-09-16 20:06:28,493 INFO    :        | end of iter   2 | time:  4.21s | train loss 1.3249 | 
2020-09-16 20:06:36,896 INFO    :        | end of iter   4 | time:  4.14s | train loss 1.3101 | 
2020-09-16 20:06:45,343 INFO    :        | end of iter   6 | time:  4.22s | train loss 1.3106 | 
2020-09-16 20:06:53,803 INFO    :        | end of iter   8 | time:  4.19s | train loss 1.2953 | 
2020-09-16 20:07:02,208 INFO    :        | end of iter  10 | time:  4.17s | train loss 1.3125 | 
2020-09-16 20:07:10,567 INFO    :        | end of iter  12 | time:  4.11s | train loss 1.2950 | 
2020-09-16 20:07:19,671 INFO    :        | end of iter  14 | time:  4.91s | train loss 1.2825 | 
2020-09-16 20:07:28,282 INFO    :        | end of iter  16 | time:  4.36s | train loss 1.2595 | 
2020-09-16 20:07:37,016 INFO    :        | end of iter  18 | time:  4.47s | train loss 1.2948 | 
2020-09-16 20:07:45,633 INFO    :        | end of iter  20 | time:  4.42s | train loss 1.2711 | 
2020-09-16 20:07:53,933 INFO    :        | end of iter  22 | time:  4.11s | train loss 1.3126 | 
2020-09-16 20:08:02,210 INFO    :        | end of iter  24 | time:  4.12s | train loss 1.2832 | 
2020-09-16 20:08:10,559 INFO    :        | end of iter  26 | time:  4.17s | train loss 1.2711 | 
2020-09-16 20:08:18,839 INFO    :        | end of iter  28 | time:  4.13s | train loss 1.3226 | 
2020-09-16 20:08:27,132 INFO    :        | end of iter  30 | time:  4.16s | train loss 1.2876 | 
2020-09-16 20:08:36,428 INFO    :        | end of iter  32 | time:  4.72s | train loss 1.2938 | 
2020-09-16 20:08:45,857 INFO    :        | end of iter  34 | time:  4.47s | train loss 1.2504 | 
2020-09-16 20:08:54,130 INFO    :        | end of iter  36 | time:  4.10s | train loss 1.2956 | 
2020-09-16 20:09:02,391 INFO    :        | end of iter  38 | time:  4.11s | train loss 1.2625 | 
2020-09-16 20:09:11,536 INFO    :        | end of iter  40 | time:  4.91s | train loss 1.2778 | 
2020-09-16 20:09:20,733 INFO    :        | end of iter  42 | time:  4.69s | train loss 1.2787 | 
2020-09-16 20:09:30,006 INFO    :        | end of iter  44 | time:  4.63s | train loss 1.2539 | 
2020-09-16 20:09:39,817 INFO    :        | end of iter  46 | time:  4.82s | train loss 1.2479 | 
2020-09-16 20:09:48,448 INFO    :        | end of iter  48 | time:  4.23s | train loss 1.2663 | 
2020-09-16 20:09:57,307 INFO    :        | end of iter  50 | time:  4.37s | train loss 1.2488 | 
2020-09-16 20:10:06,490 INFO    :        | end of iter  52 | time:  4.44s | train loss 1.2282 | 
2020-09-16 20:10:15,382 INFO    :        | end of iter  54 | time:  4.48s | train loss 1.2357 | 
2020-09-16 20:10:24,331 INFO    :        | end of iter  56 | time:  4.32s | train loss 1.2640 | 
2020-09-16 20:10:32,638 INFO    :        | end of iter  58 | time:  4.10s | train loss 1.2369 | 
2020-09-16 20:10:41,239 INFO    :        | end of iter  60 | time:  4.45s | train loss 1.2367 | 
2020-09-16 20:10:49,915 INFO    :        | end of iter  62 | time:  4.36s | train loss 1.2695 | 
2020-09-16 20:10:58,514 INFO    :        | end of iter  64 | time:  4.23s | train loss 1.3059 | 
2020-09-16 20:11:07,252 INFO    :        | end of iter  66 | time:  4.49s | train loss 1.2691 | 
2020-09-16 20:11:15,723 INFO    :        | end of iter  68 | time:  4.24s | train loss 1.2083 | 
2020-09-16 20:11:24,507 INFO    :        | end of iter  70 | time:  4.22s | train loss 1.2577 | 
2020-09-16 20:11:33,083 INFO    :        | end of iter  72 | time:  4.33s | train loss 1.2262 | 
2020-09-16 20:11:41,788 INFO    :        | end of iter  74 | time:  4.29s | train loss 1.2380 | 
2020-09-16 20:11:51,283 INFO    :        | end of iter  76 | time:  4.90s | train loss 1.2529 | 
2020-09-16 20:12:00,504 INFO    :        | end of iter  78 | time:  4.16s | train loss 1.2814 | 
2020-09-16 20:12:09,910 INFO    :        | end of iter  80 | time:  4.86s | train loss 1.2065 | 
2020-09-16 20:12:19,191 INFO    :        | end of iter  82 | time:  4.94s | train loss 1.2527 | 
2020-09-16 20:12:28,627 INFO    :        | end of iter  84 | time:  4.66s | train loss 1.2183 | 
2020-09-16 20:12:36,902 INFO    :        | end of iter  86 | time:  4.12s | train loss 1.1924 | 
2020-09-16 20:12:45,241 INFO    :        | end of iter  88 | time:  4.18s | train loss 1.2609 | 
2020-09-16 20:12:53,604 INFO    :        | end of iter  90 | time:  4.17s | train loss 1.2123 | 
2020-09-16 20:13:02,546 INFO    :        | end of iter  92 | time:  4.32s | train loss 1.2075 | 
2020-09-16 20:13:11,818 INFO    :        | end of iter  94 | time:  4.93s | train loss 1.2244 | 
2020-09-16 20:13:20,304 INFO    :        | end of iter  96 | time:  4.14s | train loss 1.1895 | 
2020-09-16 20:13:29,023 INFO    :        | end of iter  98 | time:  4.49s | train loss 1.2139 | 
2020-09-16 20:13:38,099 INFO    :        | end of iter 100 | time:  4.87s | train loss 1.1900 | 
2020-09-16 20:13:47,584 INFO    :        | end of iter 102 | time:  4.63s | train loss 1.2029 | 
2020-09-16 20:13:55,999 INFO    :        | end of iter 104 | time:  4.14s | train loss 1.1736 | 
2020-09-16 20:14:05,136 INFO    :        | end of iter 106 | time:  4.88s | train loss 1.2697 | 
2020-09-16 20:14:13,952 INFO    :        | end of iter 108 | time:  4.32s | train loss 1.2231 | 
2020-09-16 20:14:22,712 INFO    :        | end of iter 110 | time:  4.42s | train loss 1.1754 | 
2020-09-16 20:14:31,265 INFO    :        | end of iter 112 | time:  4.14s | train loss 1.1917 | 
2020-09-16 20:14:39,833 INFO    :        | end of iter 114 | time:  4.34s | train loss 1.1854 | 
2020-09-16 20:14:48,176 INFO    :        | end of iter 116 | time:  4.16s | train loss 1.1925 | 
2020-09-16 20:14:56,424 INFO    :        | end of iter 118 | time:  4.10s | train loss 1.2220 | 
2020-09-16 20:15:04,697 INFO    :        | end of iter 120 | time:  4.13s | train loss 1.2326 | 
2020-09-16 20:15:13,697 INFO    :        | end of iter 122 | time:  4.80s | train loss 1.1478 | 
2020-09-16 20:15:22,319 INFO    :        | end of iter 124 | time:  4.14s | train loss 1.1811 | 
2020-09-16 20:15:31,547 INFO    :        | end of iter 126 | time:  4.93s | train loss 1.2021 | 
2020-09-16 20:15:40,815 INFO    :        | end of iter 128 | time:  4.48s | train loss 1.2044 | 
2020-09-16 20:15:50,336 ERROR   : [Error] Caught keyboard interrupt on worker. Stopping supervisor...
2020-09-16 20:15:50,345 INFO    : [INFO] Saving model to save/train/earlystop
